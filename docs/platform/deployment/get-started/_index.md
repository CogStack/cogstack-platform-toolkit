# Getting Started

This page outlines the basic setup and requirements for running CogStack

See the Quickstart guide for a tutorial that will install a local kubernetes using Minikube, and run an instance of CogStack using Helm.

## Models
The primary thing you will need to arrange is a trained model to be used for the natural language processing functionality of CogStack. We provide small free models, though to get access to better performing models please contact us

## Technologies and Tools
Our recommended deployment method is on **Kubernetes** by using **Helm** charts

These are some of the terms and technologies relevant to deploying CogStack:

- [GitOps](https://en.wikipedia.org/wiki/DevOps#GitOps)
- [Docker](https://docs.docker.com/get-docker/)
- [Terraform](https://www.terraform.io/downloads)
- [Kubernetes](https://kubernetes.io/)
- [kubectl](https://kubernetes.io/docs/tasks/tools/)
- [Helm](https://helm.sh/docs/intro/install/)
- [Ansible](https://docs.ansible.com/ansible/latest/index.html)
- [Portainer](https://www.portainer.io/)

See the official documentation on these tools for the best documentation for installation and setup. Not all of these are needed depending on which deployment method is used.

## Cloud Accounts & Permissions

If you plan to deploy on cloud providers like AWS, Azure, or OpenStack, ensure you have the appropriate accounts set up with necessary permissions. Refer to the respective providerâ€™s documentation for guidance.


## Contents
```{toctree}
:maxdepth: 2

quickstart
```
